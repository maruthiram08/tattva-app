# AI Agent Handoff Document

**Current State**: Phases 1-4 are **COMPLETE** âœ…
**Next Phase**: Phase 5 (Frontend UI) or Provider Debugging

**Last Updated**: December 16, 2025
**Session Agent**: Claude (Sonnet 4.5)

---

## ğŸ¯ Project Status

### âœ… Completed Phases

**Phase 1: Data Ingestion** (Previous agent)
- 23,402 shlokas ingested to Pinecone
- Dual-provider tag extraction (Claude + OpenAI)
- JSONL streaming format for large datasets
- ~168k tags extracted (characters, events, themes)

**Phase 2: Classification & Template System** (This session)
- 45-category classification system with hybrid approach (rule-based + LLM)
- 3 template types (T1/T2/T3) with hard constraint validation
- Zod schemas for runtime type checking
- Classification API: `POST /api/classify`

**Phase 3: Retrieval Pipeline** (This session)
- Category-specific retrieval configurations for all 45 categories
- Pinecone integration with metadata filtering
- Retrieval API: `POST /api/retrieve`
- Semantic search with OpenAI embeddings (text-embedding-3-small)

**Phase 4: Multi-Provider LLM & Answer Assembly** (This session)
- 3 LLM providers: Claude, OpenAI, Gemini
- Template-specific prompts (T1/T2/T3)
- Complete RAG pipeline: Classify â†’ Retrieve â†’ Generate â†’ Validate
- Answer Assembly API: `POST /api/answer`
- Validation with retry logic (max 2 attempts)

### ğŸ”„ Ready for Next Phase

**Phase 5: Frontend UI** (Recommended next)
- Build React components for answer display (T1/T2/T3)
- Question input with validation
- Citation tooltips and expansion
- Responsive design (desktop/tablet/mobile)
- About & Limits page

**Phase 6: Evaluation System** (Alternative)
- 30 golden questions dataset from PRD
- Automated testing API
- CI integration with GitHub Actions

---

## ğŸ—ï¸ Architecture Overview

### Complete RAG Pipeline

```
User Question
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 1: CLASSIFICATION                 â”‚
â”‚  API: POST /api/classify                â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚  â€¢ Rule-based pre-filtering (4-235ms)   â”‚
â”‚    - Explicit references                â”‚
â”‚    - Character names                    â”‚
â”‚    - Out-of-scope patterns              â”‚
â”‚  â€¢ LLM classification (1.3-3.2s)        â”‚
â”‚    - GPT-4o with JSON mode              â”‚
â”‚    - Returns: category, template,       â”‚
â”‚      confidence, reasoning              â”‚
â”‚  Output: CategoryId (1-45), Template    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 2: RETRIEVAL                      â”‚
â”‚  API: POST /api/retrieve                â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚  â€¢ Generate query embedding             â”‚
â”‚  â€¢ Apply category-specific filters:     â”‚
â”‚    - TopK (5-50 shlokas)                â”‚
â”‚    - Granularity (shloka/sarga/kanda)   â”‚
â”‚    - Metadata (has_translation, etc.)   â”‚
â”‚  â€¢ Query Pinecone with filters          â”‚
â”‚  â€¢ Check for missing data               â”‚
â”‚  Output: Retrieved shlokas with context â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 3: PROMPT BUILDING                â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚  â€¢ Load template prompt (T1/T2/T3)      â”‚
â”‚  â€¢ Inject question + retrieved context  â”‚
â”‚  â€¢ Format citations (kanda/sarga/shloka)â”‚
â”‚  Output: Complete LLM prompt            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 4: LLM GENERATION                 â”‚
â”‚  API: POST /api/answer                  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚  â€¢ Select provider (OpenAI/Claude/Gemini)â”‚
â”‚  â€¢ Call provider.generateAnswer()       â”‚
â”‚  â€¢ Parse JSON response                  â”‚
â”‚  Output: Raw answer (unvalidated)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 5: VALIDATION                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚  â€¢ Template structure (Zod schemas)     â”‚
â”‚  â€¢ Hard constraints:                    â”‚
â”‚    T1: No speculation words             â”‚
â”‚    T2: Must have "Limit of Certainty"   â”‚
â”‚    T3: No apology language              â”‚
â”‚  â€¢ Citation format check                â”‚
â”‚  â€¢ Retry if invalid (max 2 attempts)    â”‚
â”‚  Output: Validated answer + metadata    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Structured Answer Card (JSON)
```

### Performance Metrics

| Stage | Time | Cost (per query) |
|-------|------|------------------|
| Classification (rule-based) | 4-235ms | $0 |
| Classification (LLM) | 1.3-3.2s | ~$0.001 |
| Retrieval (Pinecone) | 3-20s | ~$0.0001 |
| Answer Generation | 15-30s | $0.015-$0.025 |
| **Total Pipeline** | **~26.5s** | **$0.016-$0.026** |

---

## ğŸ“ File Structure

### New Files Created (18 total)

```
lib/
â”œâ”€â”€ types/
â”‚   â”œâ”€â”€ templates.ts              # T1/T2/T3 answer types, CategoryId
â”‚   â”œâ”€â”€ retrieval.ts               # Retrieval types, ShlokaMetadata
â”‚   â””â”€â”€ llm-provider.ts            # ILLMProvider interface
â”œâ”€â”€ data/
â”‚   â””â”€â”€ categories.ts              # 45 category definitions
â”œâ”€â”€ config/
â”‚   â””â”€â”€ retrieval-configs.ts       # Retrieval rules for 45 categories
â”œâ”€â”€ validators/
â”‚   â””â”€â”€ template-validator.ts      # Zod schemas + constraint checking
â”œâ”€â”€ prompts/
â”‚   â”œâ”€â”€ classification-prompt.ts   # GPT-4o classification prompt
â”‚   â”œâ”€â”€ t1-textual-prompt.ts       # T1 answer generation prompt
â”‚   â”œâ”€â”€ t2-interpretive-prompt.ts  # T2 answer generation prompt
â”‚   â””â”€â”€ t3-refusal-prompt.ts       # T3 refusal prompt
â””â”€â”€ llm/
    â”œâ”€â”€ provider-factory.ts        # Provider creation/selection
    â””â”€â”€ providers/
        â”œâ”€â”€ claude-provider.ts     # Claude 3 Sonnet implementation
        â”œâ”€â”€ openai-provider.ts     # GPT-4o implementation
        â””â”€â”€ gemini-provider.ts     # Gemini Pro implementation

app/api/
â”œâ”€â”€ classify/route.ts              # Classification endpoint
â”œâ”€â”€ retrieve/route.ts              # Retrieval endpoint
â”œâ”€â”€ answer/route.ts                # Complete pipeline endpoint
â””â”€â”€ providers/route.ts             # List available providers
```

### Modified Files
- `package.json` - Added `@google/generative-ai`
- `.env.local` - Added GEMINI_API_KEY, ANTHROPIC_API_KEY

---

## ğŸ”‘ Key Components

### 1. Classification System

**File**: `app/api/classify/route.ts`

**Two-Tier Approach:**

**Tier 1: Rule-Based Pre-Filtering** (Fast Path: 4-235ms)
```typescript
// Explicit shloka references â†’ Category 34
if (/\b(shloka|sarga|kanda)\s+\d+/i.test(question)) {
  return { categoryId: 34, template: 'T1', ... };
}

// Kanda overview â†’ Category 2
if (/what happens in (bala|ayodhya|...) kanda/i.test(question)) {
  return { categoryId: 2, template: 'T1', ... };
}

// Out-of-scope â†’ Category 45 (refusal)
if (/by (modern|today's|current) standards/i.test(question)) {
  return { categoryId: 45, template: 'T3', ... };
}
```

**Tier 2: LLM Classification** (Fallback: 1.3-3.2s)
- GPT-4o with `response_format: { type: 'json_object' }`
- Temperature: 0.1 for consistency
- Returns structured classification with reasoning

**Categories**: 45 total, grouped as:
- Story/Episode (1-15): Epic overview, Kanda/Sarga summaries, character episodes
- Character (16-25): Identity, relationships, evolution, motivations
- Dharma (26-33): Concepts, dilemmas, consequences, teachings
- Verse (34-40): Specific shloka meanings, word-by-word translation
- Interpretation (41-43): Symbolism, modern relevance, comparisons
- Meta (44-45): Scope explanation, refusals

### 2. Retrieval Configuration

**File**: `lib/config/retrieval-configs.ts`

**Category-Specific Rules:**

| Example Category | Granularity | TopK | Filters |
|-----------------|-------------|------|---------|
| 1 (Epic overview) | kanda | 50 | - |
| 2 (Kanda overview) | kanda | 30 | - |
| 16 (Character identity) | multi-shloka | 15 | - |
| 25 (Character evolution) | sarga-range | 25 | `has_comments: true` |
| 34 (Specific shloka) | shloka | 5 | `has_translation: true` |
| 45 (Refusal) | shloka | 0 | (no retrieval) |

**Why Different Configs?**
- **T2 (Interpretive)** needs scholarly commentary â†’ filter `has_comments: true`
- **Verse questions** need word-by-word â†’ filter `has_translation: true`
- **Refusals (T3)** don't need context â†’ topK = 0

### 3. Template Validation

**File**: `lib/validators/template-validator.ts`

**Hard Constraints:**

**T1 (Textual) - No Speculation:**
```typescript
const SPECULATION_PATTERNS = [
  /\b(might|may|could|would|possibly|perhaps|probably|likely)\b/i,
  /\b(seems|appears|suggests|implies|indicates)\b/i,
];

// Validation fails if speculation detected
if (containsSpeculation(answer.answer)) {
  errors.push({
    field: 'answer',
    message: 'T1 answers must not contain speculative language',
    constraint: 'no_speculation',
  });
}
```

**T2 (Interpretive) - Mandatory "Limit of Certainty":**
```typescript
if (!answer.limitOfCertainty || answer.limitOfCertainty.trim().length < 10) {
  errors.push({
    field: 'limitOfCertainty',
    message: 'T2 answers MUST include "Limit of Certainty" section',
    constraint: 'mandatory_field',
  });
}
```

**T3 (Refusal) - No Apologies:**
```typescript
const APOLOGY_PATTERNS = [
  /\b(sorry|apolog|unfortunately|regret|afraid)\b/i,
];

if (containsApology(answer.outOfScopeNotice)) {
  errors.push({
    field: 'outOfScopeNotice',
    message: 'T3 refusals must not apologize',
    constraint: 'no_apologies',
  });
}
```

### 4. Multi-Provider System

**File**: `lib/llm/provider-factory.ts`

**Three Providers:**

| Provider | Model | Cost (Input/Output per 1M tokens) | Status |
|----------|-------|-----------------------------------|--------|
| **OpenAI** | gpt-4o | $2.5 / $10 | âœ… Working |
| **Claude** | claude-3-sonnet-20240229 | $3 / $15 | âŒ 404 errors |
| **Gemini** | gemini-pro | $1.25 / $5 (cheapest!) | âŒ Cache issue |

**Provider Selection Logic:**
```typescript
export function getDefaultProvider(): LLMProvider {
  // 1. Check env variable
  const envProvider = process.env.DEFAULT_LLM_PROVIDER;
  if (envProvider && isValid(envProvider)) return envProvider;

  // 2. Fallback order: Claude > OpenAI > Gemini
  if (process.env.ANTHROPIC_API_KEY) return 'claude';
  if (process.env.OPENAI_API_KEY) return 'openai';
  if (process.env.GEMINI_API_KEY) return 'gemini';

  throw new Error('No LLM provider API keys configured');
}
```

**Provider Interface:**
```typescript
interface ILLMProvider {
  name: LLMProvider;
  generateAnswer(request: LLMGenerateRequest): Promise<LLMGenerateResponse>;
  isAvailable(): boolean;
}
```

### 5. Answer Assembly Pipeline

**File**: `app/api/answer/route.ts`

**Complete Orchestration:**
```typescript
async function POST(request: NextRequest) {
  // Step 1: Classification
  const classification = await classifyQuestion(question);
  // â†’ { categoryId: 16, template: 'T1', confidence: 0.95, ... }

  // Step 2: Retrieval (skip for refusals)
  let retrieval = { shlokas: [], totalRetrieved: 0 };
  if (classification.shouldAnswer && classification.template !== 'T3') {
    retrieval = await retrieveContext(question, classification.categoryId);
    // â†’ { shlokas: [...15 shlokas...], totalRetrieved: 15 }
  }

  // Step 3: Select provider
  const provider = requestedProvider || getDefaultProvider();

  // Step 4: Build prompt
  const prompt = buildPrompt(
    classification.template,
    question,
    classification.categoryName,
    retrieval
  );

  // Step 5: Generate with retry logic
  let answer = null;
  let attempt = 0;
  const MAX_RETRIES = 2;

  while (attempt < MAX_RETRIES && !answer) {
    attempt++;
    const generated = await generateAnswer(prompt, provider);
    const validation = validateAnswer(generated);

    if (validation.valid) {
      answer = generated;
    } else {
      console.error('Validation failed:', validation.errors);
      // Retry with additional constraints
    }
  }

  // Step 6: Return complete response
  return NextResponse.json({
    success: true,
    answer,
    metadata: { question, category, retrieval, generation, duration }
  });
}
```

---

## ğŸ§ª Test Results

### Classification API

**7 test questions - 100% accuracy:**

| Question | Expected Category | Actual | Time | Method |
|----------|------------------|--------|------|--------|
| "What is the Ramayana about?" | 1 (Epic overview) | âœ… 1, T1 | 3.2s | LLM |
| "Why did Rama accept exile?" | 21 (Duty-driven) | âœ… 21, T1 | 2.8s | LLM |
| "Is Rama better than Jesus?" | 45 (Refusal) | âœ… 45, T3 | 1.3s | LLM |
| "Is Rama better by modern standards?" | 45 (Refusal) | âœ… 45, T3 | 4ms | Rule-based |
| "What happens in Bala Kanda?" | 2 (Kanda overview) | âœ… 2, T1 | 235ms | Rule-based |
| "Who is Hanuman?" | 16 (Character identity) | âœ… 16, T1 | 2.7s | LLM |
| "How does Rama evolve during exile?" | 25 (Character evolution) | âœ… 25, T2 | 2.0s | LLM |

### Retrieval API

**5 test queries - all successful:**

| Question | Category | TopK | Retrieved | Top Result Quality |
|----------|----------|------|-----------|-------------------|
| "What happens in Bala Kanda?" | 2 | 30 | 30 | Various Bala Kanda shlokas |
| "Who is Hanuman?" | 16 | 15 | 15 | **Bala Kanda 17.15** (Hanuman's birth!) âœ… |
| "How does Rama evolve?" | 25 | 25 | 25 | All have `comments` field âœ… |
| "Is Rama better than Jesus?" | 45 | 0 | 0 | (Refusal - no retrieval) âœ… |
| "What does this shloka mean?" | 34 | 5 | 5 | All have `translation` field âœ… |

**Quality Note:** Semantic search is highly accurate! "Who is Hanuman?" correctly returned Bala Kanda 17.15 (which describes Hanuman's birth) as the top match.

### End-to-End Pipeline

**Test:** "Who is Hanuman?" with OpenAI provider

**Result:**
```json
{
  "success": true,
  "answer": {
    "templateType": "T1",
    "answer": "Hanuman is the son of Vayu, the Windgod, and is known for his strength, speed, and intelligence. He is a prominent vanara (monkey) and a devoted servant of Rama.",
    "textualBasis": {
      "kanda": "Sundara Kanda",
      "sarga": [1, 2, 64],
      "shloka": [15, 181, 5, 30],
      "citations": [
        "Bala Kanda 17.15",
        "Sundara Kanda 1.181",
        "Sundara Kanda 2.5",
        "Sundara Kanda 64.30"
      ]
    },
    "explanation": "Hanuman is described as 'à¤®à¤¾à¤°à¥à¤¤à¤¸à¥à¤¯à¤¾à¤¤à¥à¤®à¤œà¤ƒ' (son of Vayu) and 'à¤µà¥€à¤°à¥à¤¯à¤µà¤¤à¤¾à¤‚ à¤¶à¥à¤°à¥‡à¤·à¥à¤ à¤ƒ' (exalted among the courageous)..."
  },
  "metadata": {
    "category": { "id": 16, "name": "Character identity", "template": "T1" },
    "retrieval": { "totalShlokas": 15 },
    "generation": { "provider": "openai", "attempts": 1 },
    "duration": 26567
  }
}
```

**Validation:**
- âœ… No speculative language detected
- âœ… All citations properly formatted
- âœ… Sanskrit terms with translations
- âœ… Textual basis complete
- âœ… Template structure valid

**Pipeline Breakdown:**
- Classification: 4.8s
- Retrieval: 9.8s
- Generation: 11.5s
- Validation: < 0.1s
- **Total: 26.5 seconds**

---

## âš ï¸ Known Issues

### 1. Provider-Specific Issues

**Claude (Anthropic):**
- **Status**: âŒ Not working
- **Error**: `404 NotFoundError: model: claude-3-5-sonnet-20241022`
- **Attempted Model IDs**:
  - `claude-3-5-sonnet-20241022` â†’ 404
  - `claude-3-5-sonnet-20240620` â†’ 404
  - `claude-3-sonnet-20240229` â†’ Currently set (untested)
- **Possible Cause**: API key may not have access to 3.5 Sonnet versions
- **Next Steps**:
  - Verify API key has correct model access in Anthropic Console
  - Try model alias `claude-3-5-sonnet-latest` instead of snapshot ID
  - Contact Anthropic support if issue persists

**Gemini (Google):**
- **Status**: âŒ Not working
- **Error**: `models/gemini-1.5-pro is not found for API version v1beta`
- **Issue**: Next.js caching issue
  - Code shows `gemini-pro` (correct)
  - Runtime logs show `gemini-1.5-pro` (old cached version)
- **Fix**: Restart dev server to clear module cache
  ```bash
  # Kill current dev server
  pkill -f "next dev"

  # Restart
  npm run dev
  ```

**OpenAI:**
- **Status**: âœ… **FULLY WORKING**
- **Model**: gpt-4o
- **No issues**

### 2. Template Testing Coverage

**Only T1 tested so far:**
- âœ… **T1 (Textual)**: Fully tested with "Who is Hanuman?"
  - Validation: No speculation âœ…
  - Citations: Properly formatted âœ…
  - Sanskrit terms: Included âœ…

- â³ **T2 (Interpretive)**: Not tested yet
  - Test question suggestion: "How does Rama evolve during exile?"
  - Need to verify: "Limit of Certainty" section is mandatory
  - Need to verify: Separation of facts vs. interpretations

- â³ **T3 (Refusal)**: Classification tested, generation not tested
  - Test question suggestion: "Is Rama better than Jesus?"
  - Need to verify: No apology language
  - Need to verify: Alternative questions provided

### 3. Data Quality

**From Phase 1 ingestion:**
- 15.3% missing translations
- 16% missing explanations
- 97.4% missing comments (very few shlokas have scholarly commentary)

**Impact:**
- T2 (Interpretive) questions requiring comments may fail retrieval
- Verse-focused questions may lack word-by-word translation
- System handles gracefully with warnings

### 4. Missing Features

**Citation Validation (Critical):**
- **Issue**: No hallucination detector yet
- **Risk**: LLM could fabricate citations like "Bala Kanda 999.999"
- **Solution**: Cross-check all citations against retrieved context
  ```typescript
  // Needed in lib/validators/citation-validator.ts
  function validateCitations(answer: Answer, retrievedShlokas: RetrievedShloka[]) {
    const citations = extractCitations(answer);
    for (const citation of citations) {
      const exists = retrievedShlokas.find(s => matchesCitation(s, citation));
      if (!exists) {
        throw new HallucinationError(`Fabricated citation: ${citation}`);
      }
    }
  }
  ```

**Cost Optimization:**
- No caching yet (could save 20-30% with 1-hour TTL for identical questions)
- All classifications use GPT-4o (could use GPT-3.5-Turbo for simple ones)

**Frontend:**
- No UI yet (Phase 5)
- APIs work but not user-facing

---

## ğŸš€ Quick Start Commands

### Start Dev Server
```bash
npm run dev
```

### Test Classification
```bash
curl -X POST http://localhost:3000/api/classify \
  -H "Content-Type: application/json" \
  -d '{"question": "Who is Hanuman?"}'
```

### Test Retrieval
```bash
curl -X POST http://localhost:3000/api/retrieve \
  -H "Content-Type: application/json" \
  -d '{"question": "Who is Hanuman?", "categoryId": 16}'
```

### Test Complete Pipeline (OpenAI)
```bash
curl -X POST http://localhost:3000/api/answer \
  -H "Content-Type: application/json" \
  -d '{"question": "Who is Hanuman?", "provider": "openai"}' \
  --max-time 60
```

### Test T2 (Interpretive) Template
```bash
curl -X POST http://localhost:3000/api/answer \
  -H "Content-Type: application/json" \
  -d '{"question": "How does Rama evolve during exile?", "provider": "openai"}' \
  --max-time 60
```

### Test T3 (Refusal) Template
```bash
curl -X POST http://localhost:3000/api/answer \
  -H "Content-Type: application/json" \
  -d '{"question": "Is Rama better than Jesus?", "provider": "openai"}' \
  --max-time 60
```

### List Available Providers
```bash
curl http://localhost:3000/api/providers
```

---

## ğŸ“Š Environment Variables

**Required:**
```bash
# OpenAI (Working)
OPENAI_API_KEY=sk-...

# Optional providers
ANTHROPIC_API_KEY=sk-ant-...  # Claude (currently 404 errors)
GEMINI_API_KEY=...            # Gemini (cache issue)

# Pinecone (from Phase 1)
PINECONE_API_KEY=...
PINECONE_INDEX=tattva-shlokas

# App URL for internal API calls
NEXT_PUBLIC_APP_URL=http://localhost:3000

# Optional: Override default provider
DEFAULT_LLM_PROVIDER=openai   # or 'claude' or 'gemini'
```

---

## ğŸ“‹ Next Steps for Next Agent

### Option A: Phase 5 (Frontend) - Recommended

**Why:** Backend is fully functional with OpenAI. UI is the logical next step.

**Tasks:**
1. **Landing Page** (`app/page.tsx`)
   - Hero section with app description
   - Question input component
   - Example questions

2. **Answer Display Components**
   - `components/answer/T1AnswerCard.tsx` - Textual answers
   - `components/answer/T2AnswerCard.tsx` - Interpretive answers
   - `components/answer/T3RefusalCard.tsx` - Refusals
   - Conditional rendering based on `templateType`

3. **Citation Component** (`components/answer/Citation.tsx`)
   - Hover tooltip with shloka preview
   - Click to expand full shloka text
   - Link to original location (kanda/sarga/shloka)

4. **About & Limits Page** (`app/about/page.tsx`)
   - Content from PRD Section 10
   - What Tattva can/cannot answer
   - Scope explanation

5. **Responsive Design**
   - Desktop: 2-column layout
   - Tablet: Single column
   - Mobile: Optimized for small screens

**Design System:**
- Already using Tailwind CSS
- Consider shadcn/ui components (already in plan)
- Color palette: Scholarly, neutral tones (avoid bright colors)

**Key Files to Create:**
```
components/
â”œâ”€â”€ ui/
â”‚   â”œâ”€â”€ button.tsx              # shadcn/ui
â”‚   â”œâ”€â”€ card.tsx                # shadcn/ui
â”‚   â””â”€â”€ input.tsx               # shadcn/ui
â”œâ”€â”€ question/
â”‚   â”œâ”€â”€ QuestionInput.tsx       # Main input component
â”‚   â””â”€â”€ ExampleQuestions.tsx    # Clickable examples
â”œâ”€â”€ answer/
â”‚   â”œâ”€â”€ AnswerDisplay.tsx       # Conditional renderer
â”‚   â”œâ”€â”€ T1AnswerCard.tsx        # Textual template
â”‚   â”œâ”€â”€ T2AnswerCard.tsx        # Interpretive template
â”‚   â”œâ”€â”€ T3RefusalCard.tsx       # Refusal template
â”‚   â”œâ”€â”€ Citation.tsx            # Citation tooltip/expansion
â”‚   â””â”€â”€ LoadingState.tsx        # While pipeline runs (~26s)
â””â”€â”€ layout/
    â”œâ”€â”€ Header.tsx              # Nav with About link
    â””â”€â”€ Footer.tsx              # Credits

app/
â”œâ”€â”€ page.tsx                    # Landing page
â”œâ”€â”€ about/page.tsx              # About & Limits
â””â”€â”€ layout.tsx                  # Root layout (already exists)
```

### Option B: Fix Multi-Provider Issues

**Why:** Good for completeness, but not critical (OpenAI works).

**Tasks:**
1. **Debug Claude 404 errors**
   - Check Anthropic API Console for model access
   - Try model alias `claude-3-5-sonnet-latest`
   - Update `lib/llm/providers/claude-provider.ts` if needed

2. **Fix Gemini caching**
   - Restart dev server
   - Test with: `"provider": "gemini"`
   - Verify `gemini-pro` model ID works

3. **Test all 3 providers end-to-end**
   - Same question with all 3 providers
   - Compare output quality
   - Document cost differences

### Option C: Test Remaining Templates (T2/T3)

**Why:** Important for validation coverage.

**Tasks:**
1. **Test T2 (Interpretive)**
   ```bash
   curl -X POST http://localhost:3000/api/answer \
     -H "Content-Type: application/json" \
     -d '{"question": "How does Rama evolve during exile?", "provider": "openai"}'
   ```
   - Verify "Limit of Certainty" section exists
   - Verify separation of facts vs. interpretations
   - Verify uses scholarly commentary (comments field)

2. **Test T3 (Refusal)**
   ```bash
   curl -X POST http://localhost:3000/api/answer \
     -H "Content-Type: application/json" \
     -d '{"question": "Is Rama better than Jesus?", "provider": "openai"}'
   ```
   - Verify no apology language
   - Verify alternative questions provided
   - Verify calm, confident tone

3. **Document results** in `projectupdates/template_test_results.md`

### Option D: Phase 6 (Evaluation System)

**Why:** Critical for production readiness and CI/CD.

**Tasks:**
1. **Create golden questions dataset** (`data/golden-questions.json`)
   - Extract 30 questions from PRD
   - Include expected: category, template, answerability
   - Include mandatory checks (citations, tone, etc.)

2. **Build Evaluation API** (`app/api/evaluate/route.ts`)
   - Run all 30 golden questions through pipeline
   - Check routing accuracy (â‰¥95%)
   - Verify template compliance (100%)
   - Validate answerability decisions (100%)

3. **Automated evaluators** (`lib/evaluators/`)
   - `routing-evaluator.ts` - Category accuracy
   - `template-evaluator.ts` - Template compliance
   - `citation-evaluator.ts` - Citation validation
   - `tone-evaluator.ts` - Tone consistency

4. **CI integration** (`.github/workflows/evaluate.yml`)
   - Run evaluation on every PR
   - Block merge if score < 95%

---

## ğŸ” Debugging Tips

### Classification Issues
```bash
# Check if rule-based filter is catching the question
# Look for "Rule-based classification:" in logs
npm run dev
# Then test with curl
```

### Retrieval Issues
```bash
# Check Pinecone directly
# Verify filters are working (has_translation, has_comments)
# Look for "Querying Pinecone:" in logs
```

### LLM Generation Issues
```bash
# Check which provider is being used
# Look for "Provider:" in logs
# Check if JSON parsing fails (LLM didn't return valid JSON)
```

### Validation Failures
```bash
# Check which constraints are failing
# Look for "Validation failed:" in logs
# Common issues:
#   - T1: Contains speculation words (might, could, etc.)
#   - T2: Missing "Limit of Certainty" section
#   - T3: Contains apology language (sorry, unfortunately, etc.)
```

---

## ğŸ“š Additional Resources

**Documentation Created:**
- `projectupdates/phase2_3_4_session_report.md` - Complete session report
- `projectupdates/api_test_results.md` - API test results (from earlier)
- `projectupdates/multi_provider_llm.md` - Multi-provider notes (from earlier)

**Original Plan:**
- `.claude/plans/delegated-finding-rabbit.md` - 9-week implementation plan

**PRD Reference:**
- Check project root for PRD with 30 golden questions

---

**Last Session Summary:**
- Built complete RAG pipeline (Phases 2-4)
- 18 new files created
- 100% classification accuracy on test questions
- End-to-end pipeline working with OpenAI (26.5s, $0.016-0.026 per query)
- Ready for frontend development or template testing

**Recommendations:**
1. **Start with Phase 5 (Frontend)** - Most critical path
2. **Test T2/T3 templates** - Important validation
3. **Fix Claude/Gemini** - Nice to have, not blocking
4. **Phase 6 (Evaluation)** - Production readiness

Good luck! ğŸš€


## ğŸ”„ Session Update (Dec 17, 2025)

### âœ… Completed Tasks

1. **Refactoring (Service Extraction)**
   - Extracted `api/classify` logic to `lib/services/classification-service.ts`
   - Extracted `api/retrieve` logic to `lib/services/retrieval-service.ts`
   - Updated `answer-service.ts` to use direct service calls instead of internal HTTP fetch
   - **Result**: Fixed production `fetch failed` / `ECONNREFUSED` error on Vercel.

2. **UI Improvements**
   - **Loading States**: Implemented `TattvaLoader` (Spinning Favicon) for global transitions (Root, Explorer, About).
   - **Mobile Header**: Fixed clipping issue by increasing padding (`pl-6 pr-9`) and gap.
   - **Search Bar**: Implemented "Expand on Tap" animation and updated placeholder to "Ask Tattva...".
   - **Sarga Page**: Added loading spinner for transitions between Kanda and Sarga pages.

3. **Deployment**
   - Successfully deployed to Vercel (needs manual push for final confirmation).

